{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from scrap_utils import Quote, convert_manual_author, extrat_quote, tokenize, get_babelio_citation, scrap_recent_babelio\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "\n",
    "def extract_poems_eclair(url = \"https://www.eternels-eclairs.fr/poemes-prevert.php\"):\n",
    "    response = requests.get(url)\n",
    "    html_content = response.content # .decode('utf-8')\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    poems = []\n",
    "    for ii, card in enumerate(soup.find_all('div', class_='card')):\n",
    "        try:\n",
    "            # (text, title, book, auteur))\n",
    "            if card.find('div', class_='poeme-texte') is not None:\n",
    "                text = '\\n'.join([str(x) for x in card.find('div', class_='poeme-texte').p.contents]).replace('\\n<br/>\\n', '\\n').replace('<br/>', '').strip()\n",
    "            elif card.find('p', class_='respecter-espaces-bruts') is not None:\n",
    "                text = card.find('p', class_='respecter-espaces-bruts').text.strip()\n",
    "            else:\n",
    "                text = card.find('div', class_='poeme-texte haiku').text.strip()\n",
    "            try:\n",
    "                title = card.h3.text.strip()\n",
    "            except:\n",
    "                title = None\n",
    "            try:\n",
    "                book = card.find('figcaption').cite.text.strip() # book\n",
    "            except:\n",
    "                book = None\n",
    "            auteur = card.find('figcaption').text.split(\"\\n\")[1].strip()[2:]\n",
    "            poems.append(Quote(text, author = auteur, book = book,\n",
    "                               source = 'eternels-eclairs', title=title,\n",
    "                               url = url))\n",
    "        except Exception as e:\n",
    "            try:\n",
    "                text = card.p.text\n",
    "                title = card.h3.text\n",
    "                figure_element = card.find('figure')\n",
    "                figcaption_element = figure_element.find('figcaption')\n",
    "                author_and_book = figcaption_element.text.strip()\n",
    "                author, book = author_and_book.split(',', 1)\n",
    "                author = author.strip()[2:]\n",
    "                book = book.strip()\n",
    "                poems.append(Quote(text, author = author, book = book,\n",
    "                               source = 'eternels-eclairs', title=title,\n",
    "                               url = url))\n",
    "            except Exception as e:\n",
    "                if ii > 0:\n",
    "                    print(ii, \"Error:\", e) #, e.__class__, e.__class__.__name__)\n",
    "                    # print(card)\n",
    "    return poems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'data-recommender-v2v-bY9wBxfx-py3.9 (Python 3.9.16)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/t.schmitt/Library/Caches/pypoetry/virtualenvs/data-recommender-v2v-bY9wBxfx-py3.9/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# !python -m pip install pyperclip\n",
    "\n",
    "# # import streamlit.components.v1 as components\n",
    "# from streamlit_extras.let_it_rain import rain\n",
    "# # import streamlit_antd_components as sac\n",
    "# from st_keyup import st_keyup\n",
    "# import streamlit_wordcloud as wordcloud\n",
    "\n",
    "# pip install streamlit-wordcloud\n",
    "# pip install extra-streamlit-components\n",
    "# pip install streamlit-keyup\n",
    "# pip install streamlit-extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyperclip in /Users/t.schmitt/miniconda3/lib/python3.10/site-packages (1.9.0)\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install pyperclip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "l_url = \"\"\"https://www.eternels-eclairs.fr/poemes-prevert.php\n",
    "https://www.eternels-eclairs.fr/poemes-chansons-textes-paroles-jacques-brel.php\n",
    "https://www.eternels-eclairs.fr/poemes-victor-hugo.php\n",
    "https://www.eternels-eclairs.fr/poemes-jean-de-la-fontaine.php\n",
    "https://www.eternels-eclairs.fr/poemes-rimbaud.php\n",
    "https://www.eternels-eclairs.fr/poemes-rilke.php\n",
    "https://www.eternels-eclairs.fr/poemes-apollinaire.php\n",
    "https://www.eternels-eclairs.fr/poemes-eluard.php\n",
    "https://www.eternels-eclairs.fr/poemes-maurice-careme.php\n",
    "https://www.eternels-eclairs.fr/poemes-baudelaire.php\n",
    "https://www.eternels-eclairs.fr/poemes-verlaine.php\n",
    "https://www.eternels-eclairs.fr/anthologie-haikus-livres.php\n",
    "https://www.eternels-eclairs.fr/haikus-japonais.php\n",
    "https://www.eternels-eclairs.fr/haikus-basho-buson-issa-shiki-santoka.php\n",
    "https://www.eternels-eclairs.fr/poesie-poemes-beaux-sonnets.php\n",
    "https://www.eternels-eclairs.fr/poesie-celebre-les-plus-beaux-poemes-et-poemes-les-plus-connus.php\"\"\"\n",
    "\n",
    "l_url = l_url.split('\\n')\n",
    "# l_url = [\"https://www.eternels-eclairs.fr/poemes-verlaine.php\",]\n",
    "\n",
    "for url in l_url:\n",
    "    print(url)\n",
    "    result = extract_poems_eclair(url)\n",
    "    print(\"\\t--- nb quotes:\", len(result))\n",
    "    # print(result[0])\n",
    "    if len(result) > 0:\n",
    "        df_quote = pd.DataFrame([quote.__dict__ for quote in result])\n",
    "        df_quote.to_csv(f'data/eclair/{url[url.index(\".fr/\") + 4:][:-4]}.csv')\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poesie-celebre-les-plus-beaux-poemes-et-poemes-les-plus-connus.csv (10, 15)\n",
      "poemes-chansons-textes-paroles-jacques-brel.csv (13, 15)\n",
      "poemes-victor-hugo.csv (16, 15)\n",
      "poesie-poemes-beaux-sonnets.csv (16, 15)\n",
      "poemes-rilke.csv (17, 15)\n",
      "poemes-apollinaire.csv (10, 15)\n",
      "poemes-prevert.csv (13, 15)\n",
      "poemes-eluard.csv (11, 15)\n",
      "poemes-maurice-careme.csv (16, 15)\n",
      "poemes-baudelaire.csv (13, 15)\n",
      "poemes-verlaine.csv (12, 15)\n",
      "poemes-rimbaud.csv (13, 15)\n",
      "haikus-japonais.csv (47, 15)\n",
      "anthologie-haikus-livres.csv (68, 15)\n",
      "haikus-basho-buson-issa-shiki-santoka.csv (66, 15)\n",
      "poemes-jean-de-la-fontaine.csv (15, 15)\n",
      "Done.\n",
      " ---  (356, 15)\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# + sonnet best_poemes (remove double \\n)\n",
    "# + haiku (remove long spaces)\n",
    "\n",
    "babe = os.listdir(\"data/eclair\")\n",
    "ldf = []\n",
    "for file in babe:\n",
    "    df = pd.read_csv(f\"data/eclair/{file}\")\n",
    "    if \"haiku\" in file:\n",
    "        df.haiku = True\n",
    "    else:\n",
    "        df.haiku = False\n",
    "    print(file, df.shape)\n",
    "    ldf.append(df)\n",
    "\n",
    "df = pd.concat(ldf)\n",
    "print('Done.')\n",
    "print(' --- ', df.shape)\n",
    "df.to_csv('data/eclair_data.csv')\n",
    "print('Done.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating babelio data...\n",
      "Christian Bobin.csv 140\n",
      "Michel Foucault.csv 720\n",
      "Platon.csv 893\n",
      "Issa.csv 177\n",
      "Aristote.csv 279\n",
      "Paulo Coelho.csv 4381\n",
      "Fernando Pessoa.csv 40\n",
      "Christophe Andre.csv 4179\n",
      "Jacques Lacan.csv 979\n",
      "Spinoza.csv 704\n",
      "Buson Yosa.csv 208\n",
      "Shoichi Taneda.csv 87\n",
      "Jack Kerouac.csv 1014\n",
      "Paul Verlaine.csv 914\n",
      "Alain Damasio.csv 1642\n",
      "Francoise Dolto.csv 339\n",
      "Basho Matsuo.csv 438\n",
      "Philippe Jaccottet.csv 140\n",
      "Matthieu Ricard.csv 837\n",
      "Andre Breton.csv 610\n",
      "Andre Comte Sponville.csv 882\n",
      "ric Emmanuel Schmitt.csv 140\n",
      "Albert Camus.csv 100\n",
      "Shiki Masaoka.csv 103\n",
      "Ito Ogawa.csv 1423\n",
      "Natsume Soseki.csv 671\n",
      "Paul luard.csv 1687\n",
      "Rene Char.csv 1435\n",
      "Rene Barjavel.csv 480\n",
      "Andre Gide.csv 140\n",
      "Arthur Schopenhauer.csv 788\n",
      "Thomas dAnsembourg.csv 156\n",
      "Rainer Maria Rilke.csv 120\n",
      "Hiromi Kawakami.csv 310\n",
      "Charles Bukowski.csv 2039\n",
      "Marshall B Rosenberg.csv 388\n",
      "Dalai Lama.csv 550\n",
      "Frederic Lenoir.csv 360\n",
      "Gilles Deleuze.csv 462\n",
      "Michel Onfray.csv 2377\n",
      "Yasunari Kawabata.csv 619\n",
      "Friedrich Nietzsche.csv 3202\n",
      "Boris Cyrulnik.csv 2375\n",
      "Pierre Bourdieu.csv 480\n"
     ]
    }
   ],
   "source": [
    "\n",
    "babe = os.listdir(\"data/babelio\")\n",
    "ldf = []\n",
    "print('Concatenating babelio data...')\n",
    "for file in babe:\n",
    "    df = pd.read_csv(f\"data/babelio/{file}\")\n",
    "    print(file, len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-recommender-v2v-bY9wBxfx-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
